#!/bin/sh

${HADOOP_HOME}/bin/hadoop streaming    \
    -jobconf mapred.job.name="my_first_mapred"    \
    -jobconf mapred.map.tasks=20    \
    -jobconf mapred.reduce.tasks=1    \
    -mapper    "path/map.py"    \
    -reducer "path/reduce.py"    \
    -file    "python ./path/map.py"    \
    -file    "python ./path/reduce.py"    \    # -file 是该项任务中所有需要的执行文件路径
    -input "./user/input"        \
    -output "./user/output"   


#!/bin/sh

#调试模式打开
set -x
set -e
set -o pipefail

source "./base.conf"

DATE = "$1" #给个默认的日期
[ -z "$DATE" ] && DATE=`date +%Y%m%d` #短路，没给日期的话，则赋予当前系统日期

INPUT_PATH=xxxxxxxxx
OUTPUT_PATH=xxxxxxxx

${HADOOP_HOME}/bin/hadoop fs -conf "${HADOOP_CONF}" -test -e "${OUTPUT_PATH}" && {
    ${HADOOP_HOME}/bin/hadoop fs -conf ${HADOOP_CONF} -rmr ${OUTPUT_PATH}
}

${HADOOP_HOME}/bin/hadoop stream -conf ${HADOOP_CONF} \
                -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPArtitioner \
                -jobconf mapred.job.name="xxxxx" \
                -jobconf mapred.reduce.tasks="500" \
                -jobconf mapred.job.map.capacity="500" \
                -jobconf mapred.job.reduce.capacity="500" \
                -jobconf stream.memory.limit="100" \
                -jobconf mapred.job.priority="VERY_HIGH" \
                -jobconf num.key.fields.for.partition="1" \
                -input "${INPUT_PATH}" \
                -output "${OUTPUT_PATH}" \
                -file "./map_bjh_merge.py" \
                -file "./reduce_bjh_merge.py" \
                -file "./util.py" \
                -file "./base.conf" \
                -file "${HADOOP_CONF}" \
                -mapper "/noah/bin/python2.7 map_bjh_merge.py" \
                -reducer "/noah/bin/python2.7 reduce_bjh_merge.py"

[ $? -ne 0 ] && echo "err!!! ${OUTPUT_PATH} generate err!" && exit 1     #是否正常运行，发现错误则输出信息
${HADOOP_HOME}/bin/hadoop fs -conf ${HADOOP_CONF} -touchz "${OUTPUT_PATH}/__SUCCESS"

exit 0
